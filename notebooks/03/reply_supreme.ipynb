{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Our task](../02/sampling_problem) has been to reply to the Supreme Court on\n",
    "their judgment in the appeal of Robert Swain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Robert Swain appealed his death sentence, for rape, on the\n",
    "basis that the jury selection was biased against black people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "His trial had a jury pool, of 100, from which the jury had to be selected.\n",
    "That jury pool should have been representative of the local population.\n",
    "\n",
    "The jury pool had 8 black people, but the local population was 26% black.\n",
    "\n",
    "If the jury pool had been representative, we would expect about 26 of 100\n",
    "people to be black.  Our question is what we mean by *about* 26 of 100.\n",
    "\n",
    "The Supreme Court thought that the difference between expected (26) and actual\n",
    "(8) was small. But was it?  Does 8 of 100 fit somewhere in our description of\n",
    "*about* 26 of 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this, we are going to *simulate* making a jury pool.\n",
    "\n",
    "Our *model* is that each juror has been randomly selected from the population.\n",
    "That is, for any one juror, there is a 0.26 probability that they are black.\n",
    "\n",
    "First we make one jury pool, of 100, to remind ourselves of the task.\n",
    "\n",
    "Then we make 10 jury pools of 100, to get warmed up.\n",
    "\n",
    "Finally we make 10000 jury pools, each of 100 members, and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the array library\n",
    "import numpy as np\n",
    "# Make the floating point numbers print nicely.\n",
    "# This does not affect the calculations, only the display.\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one jury pool, and the number of black people we get in our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make 100 random numbers between 0 and 1\n",
    "randoms = np.random.uniform(size=100)\n",
    "# Say values < 0.26 correspond to black jurors.\n",
    "black_yn = randoms < 0.26\n",
    "# We now have True for black jurors and False otherwise.\n",
    "# Count the number of Trues\n",
    "np.count_nonzero(black_yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is one estimate, for the number of black people we can expect, if our\n",
    "model is correct.  We can run that a few times to get a range of values.   If\n",
    "we run it only a few times, we might be unlucky, and get some results that are\n",
    "not representative.  It is safer to run it a huge number of times, to make sure\n",
    "we've got an idea of the variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do that, by using a two-dimensional array.\n",
    "\n",
    "We will start by making 10 jury pools, to get warmed up.  Later we will use\n",
    "a much higher number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an array with 10 rows, and 100 columns.\n",
    "# Each row corresponds to one jury pool\n",
    "randoms_2d = np.random.uniform(size=(10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we label each element in the array as `True` (black juror) or `False`\n",
    "(white juror)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set True for black jurors\n",
    "black_yn_2d = randoms_2d < 0.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count how many `True` values we have in each *row*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 25, 30, 30, 29, 26, 26, 26, 32, 26])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_counts = np.count_nonzero(black_yn_2d, axis=1)\n",
    "black_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these values is one estimate for how many black jurors we should\n",
    "expect, if our model is right.  Already we get the feeling that 8 is rather\n",
    "unlikely, if our model is correct.  But - how unlikely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better estimate, let us do the same thing, but with 10000 jury pools,\n",
    "and therefore, 10000 estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms_2d_big = np.random.uniform(size=(10000, 100))\n",
    "black_yn_big = randoms_2d_big < 0.26\n",
    "black_counts_big = np.count_nonzero(black_yn_big, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran this cell yourself, you will notice that it runs very fast, in much\n",
    "less than a second, on a reasonable laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 10000 estimates, one for each row in the original array, and\n",
    "therefore, one for each simulated jury pool.\n",
    "\n",
    "Remember, the function `len` shows us the length of the array, and therefore,\n",
    "the number of values in this one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(black_counts_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to have a look at the spread of these values.  To do this, we plot\n",
    "a histogram.  Here is how to do that, in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the plotting library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A special command to tell the Notebook to show us\n",
    "# the plots inside the Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   35.,   182.,   816.,  1862.,  2581.,  2968.,  1065.,   376.,\n",
       "           99.,    16.]),\n",
       " array([ 11. ,  14.2,  17.4,  20.6,  23.8,  27. ,  30.2,  33.4,  36.6,\n",
       "         39.8,  43. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do the histogram of our 10000 estimates.\n",
    "plt.hist(black_counts_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as if 8 is nowhere on the spread of our estimates.  How many times did\n",
    "we get a value less than or equal to 8, in all our 10000 estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_are_low = black_counts_big < 9\n",
    "np.count_nonzero(counts_are_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 10000 random jury pools, we never see a value as low as 8.  We can ask Numpy\n",
    "to show us the minimum value that we do see, by using the `np.min` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(black_counts_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have run an analysis assuming that the jurors were selected at random.  On\n",
    "that assumption, a count of 8 jurors in 1000 is incredibly unlikely.  It is so\n",
    "unlikely, that we never get a number as low as 8, in 10000 repeats.   That\n",
    "makes us think that the probability of getting 8 black people in a jury pool of\n",
    "100, is less than 1 in 10000 or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 10000"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.0",
    "jupytext_version": "0.8.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
